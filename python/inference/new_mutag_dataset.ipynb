{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4337\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path = osp.join(osp.dirname(osp.realpath(current_dir)), '../', 'datasets')\n",
    "dataset = TUDataset(path, name='Mutagenicity').shuffle()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset with the uncommon nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 677 new graphs\n",
      "New dataset:  5014\n"
     ]
    }
   ],
   "source": [
    "common_element_indices = {0, 1, 3, 4}\n",
    "\n",
    "def create_new_graph(data):\n",
    "    uncommon_elements = []\n",
    "    for i in range(data.x.shape[0]):\n",
    "        if torch.argmax(data.x[i, :]).item() not in common_element_indices:\n",
    "            uncommon_elements.append(data.x[i, :])\n",
    "\n",
    "    if len(uncommon_elements) > 0:\n",
    "        uncommon_elements = torch.stack(uncommon_elements)\n",
    "\n",
    "        num_nodes = len(uncommon_elements)\n",
    "        edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(i + 1, num_nodes)]).t().contiguous()\n",
    "        # if len(edge_index) == 0:\n",
    "        #     a = torch.tensor([[]], dtype=torch.long)\n",
    "        #     b = torch.tensor([[]], dtype=torch.long)\n",
    "        #     edge_index = torch.cat((a, b), 0)\n",
    "\n",
    "        if len(edge_index) > 0:\n",
    "            graph = Data(\n",
    "                x=uncommon_elements,\n",
    "                edge_index=edge_index,\n",
    "                y=data.y\n",
    "            )\n",
    "            return graph\n",
    "    return None\n",
    "\n",
    "new_graphs = [create_new_graph(data) for data in dataset if create_new_graph(data) is not None]\n",
    "print(\"Created \" + str(len(new_graphs)) + \" new graphs\")\n",
    "\n",
    "new_dataset = dataset + new_graphs\n",
    "\n",
    "new_loader = DataLoader(new_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"New dataset: \", len(new_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MYACRGnnGraph(\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x MYACRConv()\n",
       "  )\n",
       "  (linear): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import re\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append(\"/Users/raffaelepojer/Dev/RBN-GNN/python/\")\n",
    "from gnn.ACR_graph import *\n",
    "\n",
    "model = MYACRGnnGraph(\n",
    "    input_dim=14,\n",
    "    hidden_dim=[16,8,8],\n",
    "    num_layers=3,\n",
    "    mlp_layers=0,\n",
    "    final_read=\"add\",\n",
    "    num_classes=2,\n",
    "    fwd_dp=0.15,\n",
    "    lin_dp=0.15,\n",
    "    mlp_dp=0.0\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load(f\"/Users/raffaelepojer/Dev/RBN-GNN/models/Mutagenicity_16_8_8_20230814-204701/exp_33/rbn_acr_graph_Mutagenicity_16_8_8_add.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    for batch in data:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        target = batch.y\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "\n",
    "        tp += ((pred == 1) & (target == 1)).sum().item()\n",
    "        fp += ((pred == 1) & (target == 0)).sum().item()\n",
    "        tn += ((pred == 0) & (target == 0)).sum().item()\n",
    "        fn += ((pred == 0) & (target == 1)).sum().item()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, tn, tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5214\n",
      "Precision: 0.5282\n",
      "Recall: 0.9361\n",
      "F1 Score: 0.6754\n",
      "True Negatives: 16\n",
      "True Positives: 337\n",
      "False Negatives: 23\n",
      "False Positives: 301\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score, tn, tp, fn, fp = test(model, new_graphs)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"False Positives: {fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7563\n",
      "Precision: 0.7077\n",
      "Recall: 0.7970\n",
      "F1 Score: 0.7497\n",
      "True Negatives: 1962\n",
      "True Positives: 1830\n",
      "False Negatives: 466\n",
      "False Positives: 756\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score, tn, tp, fn, fp = test(model, new_dataset)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"False Positives: {fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7929\n",
      "Precision: 0.7664\n",
      "Recall: 0.7712\n",
      "F1 Score: 0.7688\n",
      "True Negatives: 1946\n",
      "True Positives: 1493\n",
      "False Negatives: 443\n",
      "False Positives: 455\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score, tn, tp, fn, fp = test(model, dataset)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"False Positives: {fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
